{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EigenFaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we begin, ask a friend to take a picture of you from a distance of around 1m with the default focus of ypour phone. Then, crop the image on your computer so it would contain only your face with a bit of a background. Save it with the name of \"me\" and locate it within the empty folder called \"Data\". Do not change the orders of folders. Keep the same order as in the zip file of HW3. You may also use a face out of the dataset as you would see later on but it is much more impressive if you do it with your face image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.style.use(['ggplot']) \n",
    "%matplotlib inline\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by loading a dataset of human faces out of `scikit-learn` datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "lfw_dataset = fetch_lfw_people(min_faces_per_person=0)\n",
    "_, h, w = lfw_dataset.images.shape\n",
    "X = lfw_dataset.data\n",
    "print(\"Dataset images are at the shape of {}X{}\".format(h,w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13,233 images were flattened and stacked in the matrix $X$ so every row is an image and every column is a pixel. We can see that by the shape of $X$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see some of the images of the original dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gallery(images, h, w,rows=3, cols=4):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for i in range(rows * cols):\n",
    "        plt.subplot(rows, cols, i + 1)\n",
    "        plt.imshow(images[i, :].reshape((h, w)), cmap=plt.cm.gray)\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gallery(X[0:12,:], h, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we use the `PCA` package, we have to center our data. The center of our data ($\\mu$) is the mean of each pixel along all of our images. Thus, the center has 2914 elements where the first element is the mean of all of the images' \"first\" pixels, the second is the mean of all of the images' \"second\" pixels etc. Notice that the images are already flattened in $X$ which might help you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate $\\mu$ of $X$ and center every image in $X$ (row vector) according to $\\mu$. Keep $X$ with same name `X`.\n",
    "\n",
    "**Bonus**: Applying centering without a single loop would give you extra credit points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------Implement your code here-----------------------\n",
    "\n",
    "#---------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now fit a PCA model on $X$ with 1000 components and without whitening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------Implement your code here-----------------------\n",
    "\n",
    "#---------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<span style=\"color:red\">***Question:***</span> *If we now have 1000 eigenvectors, by how many dimensions we have reduced our data?*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<span style=\"color:red\">***Answer:***</span> *answer here*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the precentage of \"energy\" preserved in these 1000 vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------Implement your code here-----------------------\n",
    "\n",
    "#---------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see these eigenfaces!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_eigenfaces(eigenvec_mat, h, w, rows=3, cols=4):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for i in range(rows * cols):\n",
    "        plt.subplot(rows, cols, i + 1)\n",
    "        plt.imshow(eigenvec_mat[i, :].reshape((h, w)), cmap=plt.cm.gray)\n",
    "        plt.title(\"$u_{\" + str(i+1) + \"}$\")\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`eigenvec_mat` is the matrix of the eigenvectors calculated where every row is an eigenvector and the first row has the highest eigenvalue and the second row has the next highest eigenvalue etc. Think where this matrix was calculated in the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvec_mat = \n",
    "plot_eigenfaces(eigenvec_mat, h, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you got it right, you should see those \"ghosts\" we talked about."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, let's move on towards the more interesting part! We will start by showing your resized gray level face image. It might be a bit distorted due to resizing. Change the format of `.jpg` as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_format = '.jpg' # change the format according to your image. Do not delete the dot sign before the format name\n",
    "image = Image.open('Data/me' + img_format)\n",
    "gray = image.convert('L')\n",
    "g = gray.resize((w, h))\n",
    "orig = np.asarray(g).astype('float32')\n",
    "plt.imshow(orig, cmap=plt.cm.gray)\n",
    "plt.grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we should flatten our image and center it by the same $\\mu$ vector you calculated before. Name the $\\mu$ vector as `mu_orig`. If you don't want\\can't use your image, or if you just want to have a sanity check, you can run the two lines (shown in comment) instead of the one above in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_img = np.asarray(g).astype('float32').flatten()\n",
    "\n",
    "# flattened_img = X[50] + mu_orig\n",
    "# orig = flattened_img.reshape((h, w))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_img -= mu_orig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set `K` to be 900 and define `U` to be the matrix containing the first K eigenvectors (rows) extracted from `eigenvec_mat`. Now, calculate the projections $c_i$ so you would have a vector with $K$ elements where the first element is $c_1$ and the second is $c_2$ etc. Relate to the pdf if you are not sure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------Implement your code here-----------------------\n",
    "\n",
    "#--------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you got it all correct, then the cell below will show you how your face is reconstructed as a linear combination of the eigenfaces which actually means that your face is a linear combination of other people's faces! The coefficients will appear with their adequate sign in the title in the left and the image constructed will appear slowly on the right.\n",
    "\n",
    "Notice the \"correction\" of the centering made in the loop for visualization.\n",
    "\n",
    "It might even work with much lower dimension such as K=600. You can try!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = np.zeros((2914,))\n",
    "fig, axes = plt.subplots(1, 2,figsize=(8,8))\n",
    "for j in range(K):\n",
    "    s += c[j]*U[j, :]\n",
    "    if np.mod(j, 10) == 0:\n",
    "        axes[0].imshow(U[j, :].reshape((h, w)), cmap=plt.cm.gray)\n",
    "        axes[0].grid(False)\n",
    "        corrected_image = s + mu_orig\n",
    "        axes[1].imshow(corrected_image.reshape((h, w)), cmap=plt.cm.gray)\n",
    "        axes[1].grid(False)\n",
    "        if c[j] < 0:\n",
    "            axes[0].set_title('{:.2f}'.format(c[j]))\n",
    "        else:\n",
    "            axes[0].set_title('+{:.2f}'.format(c[j]))\n",
    "        display(fig)\n",
    "        clear_output(wait = True)\n",
    "        plt.pause(0.3)\n",
    "        if c[j] > 0:\n",
    "            p = '+' + str(c[j])\n",
    "        else:\n",
    "            p = str(c[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2)\n",
    "axes[0].imshow(orig, cmap=plt.cm.gray) \n",
    "axes[0].title.set_text('Original')\n",
    "axes[0].grid(False)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "axes[1].imshow(corrected_image.reshape((h, w)), cmap=plt.cm.gray)\n",
    "axes[1].title.set_text('Reconstructed ')\n",
    "axes[1].grid(False)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hope you enjoyed :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
